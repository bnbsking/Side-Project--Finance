{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa65b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_dir = \"/app/dataset/preprocess/exp2\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d55a56",
   "metadata": {},
   "source": [
    "#### Input collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cac9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cap2Val:\n",
    "    multipler = {\"B\": 1e9, \"M\": 1e6}\n",
    "    \n",
    "    @classmethod\n",
    "    def cap2val(cls, s: str) -> int:\n",
    "        num = s.split(\".\")[0]\n",
    "        return int(float(num) * cls.multipler[s[-1]])\n",
    "\n",
    "\n",
    "def load_all_hist_df_and_dates(glob_path: str) -> Tuple[List[pd.Timestamp], List[pd.DataFrame]]:\n",
    "    hist_df_list = []\n",
    "    date_list = []\n",
    "    for path in sorted(glob.glob(glob_path)):\n",
    "        date = pd.to_datetime(re.findall(r\"(\\d{4}-\\d{2}-\\d{2})\", os.path.basename(path))[0])\n",
    "        date_list += [date] * 7\n",
    "        df = pd.read_excel(path)\n",
    "        df[\"Market Cap\"] = df[\"Market Cap\"].apply(lambda x: Cap2Val.cap2val(x))\n",
    "        hist_df_list += [df] * 7\n",
    "    return date_list, hist_df_list\n",
    "\n",
    "\n",
    "def get_top_n_tickers_in_window(hist_df_list_seg: List[pd.DataFrame], window_weights: List[float], top_n: int) -> List[str]:\n",
    "    assert len(hist_df_list_seg) == len(window_weights)\n",
    "    cap_dict = defaultdict(int)\n",
    "    for df, day_weight in zip(hist_df_list_seg, window_weights):\n",
    "        for _, row in df.iterrows():\n",
    "            cap_dict[row[\"Ticker\"]] += row[\"Market Cap\"] * day_weight\n",
    "    sorted_pairs = sorted(list(cap_dict.items()), key=lambda x: x[1], reverse=True)\n",
    "    top_tickers = [tick for tick, cap in sorted_pairs[:top_n]]\n",
    "    return top_tickers\n",
    "\n",
    "\n",
    "def get_weights_of_top_tickers_in_window(hist_df_list_seg: List[pd.DataFrame], top_tickers: List[str]) -> pd.DataFrame:\n",
    "    df_weights = pd.DataFrame(\n",
    "        {\n",
    "            f\"weight_{i}\": pd.Series(dtype='float') for i in range(len(top_tickers))\n",
    "        }\n",
    "    )\n",
    "    ticker_indices = {tick: i for i, tick in enumerate(top_tickers)}\n",
    "    for df in hist_df_list_seg:\n",
    "        len_df_weights = len(df_weights)\n",
    "        cap_sum = df[\"Market Cap\"].sum()\n",
    "        df[\"Weight\"] = df[\"Market Cap\"] / cap_sum\n",
    "        for _, row in df.iterrows():\n",
    "            if row[\"Ticker\"] in ticker_indices:\n",
    "                tick_idx = ticker_indices[row[\"Ticker\"]]\n",
    "                df_weights.at[len_df_weights, f\"weight_{tick_idx}\"] = row[\"Weight\"]\n",
    "    return df_weights\n",
    "\n",
    "\n",
    "class TickerMapping:\n",
    "    hist_to_price_dict = {\"SHIB\": \"1000SHIB\"}\n",
    "    price_to_hist_dict = {\"1000SHIB\": \"SHIB\"}\n",
    "\n",
    "    def hist_to_price(self, ticker: str) -> str:\n",
    "        return self.hist_to_price_dict.get(ticker, ticker)\n",
    "\n",
    "    def price_to_hist(self, ticker: str) -> str:\n",
    "        return self.price_to_hist_dict.get(ticker, ticker)\n",
    "\n",
    "\n",
    "def load_all_price_df(glob_path: str) -> Dict[str, pd.DataFrame]:\n",
    "    ticker_mapping = TickerMapping()\n",
    "    price_df_dict = {}\n",
    "    for xlsx_path in glob.glob(glob_path):\n",
    "        ticker = re.findall(\"(.*)USDT.xlsx\", os.path.basename(xlsx_path))[0]\n",
    "        ticker = ticker_mapping.price_to_hist(ticker)\n",
    "        df = pd.read_excel(xlsx_path)\n",
    "        price_df_dict[ticker] = df\n",
    "    return price_df_dict\n",
    "\n",
    "\n",
    "top_n = 15\n",
    "window_weights = [1] * 12 * 7  # 12 weeks ~ 3 months ~ 84 days\n",
    "window_size = len(window_weights)\n",
    "pred_days = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e553a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list, hist_df_list = load_all_hist_df_and_dates(\"/app/dataset/raw/20250928_现货价格数据和历史排名数据/historical_data/*.xlsx\")\n",
    "print(len(hist_df_list))\n",
    "print(date_list[0], hist_df_list[0].shape)\n",
    "\n",
    "price_df_dict = load_all_price_df(\"/app/dataset/raw/20250928_现货价格数据和历史排名数据/price_data/*.xlsx\")\n",
    "print(len(price_df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96806fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_len(df: pd.DataFrame, target_len: int):\n",
    "    if len(df) == 0:\n",
    "        df_padding = pd.DataFrame(100 + np.random.random((target_len, df.shape[1])), columns=df.columns)\n",
    "        df = pd.concat([df, df_padding], axis=0)\n",
    "    elif len(df) < target_len:\n",
    "        df_padding = pd.DataFrame([df.mean()] * (target_len - len(df)), columns=df.columns)\n",
    "        df = pd.concat([df, df_padding], axis=0)\n",
    "    elif len(df) > target_len:\n",
    "        df = df.iloc[:target_len]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def normalize_df_price(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"volume\"] = np.log(df[\"volume\"])\n",
    "    df = (df - df.min()) / (df.max() - df.min())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97e46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []  # (num_samples, window_size, total_features = tickers * features)  # data input\n",
    "price_ratio_list = []  # (num_samples, tickers + 1, pred_days - 1)  # data output\n",
    "meta_list = []\n",
    "\n",
    "for i in tqdm(range(len(hist_df_list) - window_size - pred_days)):\n",
    "    top_tickers = get_top_n_tickers_in_window(hist_df_list[i: i + window_size], window_weights, top_n)\n",
    "    #print(top_tickers)\n",
    "    df_weights = get_weights_of_top_tickers_in_window(hist_df_list[i: i + window_size], top_tickers)\n",
    "    assert df_weights.shape == (window_size, len(top_tickers))\n",
    "    #print(df_weights)\n",
    "    date_start, date_end, pred_end = date_list[i], date_list[i + window_size], date_list[i + window_size + pred_days]\n",
    "    #print(date_start, date_end, pred_end)\n",
    "    meta_list.append(\n",
    "        {\n",
    "            \"date_start\": str(date_start),\n",
    "            \"date_end\": str(date_end),\n",
    "            \"pred_end\": str(pred_end),\n",
    "            \"top_tickers\": top_tickers\n",
    "        }\n",
    "    )\n",
    "    #raise\n",
    "    \n",
    "    # iterate all tickers\n",
    "    df = pd.DataFrame([0] * window_size, columns=[\"dummy\"])  # (window_size, tickers * features)  # data input\n",
    "    price_ratio_window_list = []  # (num_tickers, pred_days - 1)  # data output\n",
    "    for j, tick in enumerate(top_tickers):\n",
    "        # (input) extract tick within start-end date + fill missing\n",
    "        df_price = price_df_dict[tick]\n",
    "        df_price = df_price[(date_start <= df_price[\"date\"]) & (df_price[\"date\"] < date_end)]\n",
    "        df_price = df_price.drop(columns=[\"date\"]).reset_index(drop=True)\n",
    "        df_price = fix_missing_len(df_price, window_size)\n",
    "        assert df_price.shape == (window_size, df_price.shape[1])\n",
    "\n",
    "        # (input) normalize + reweighting\n",
    "        df_price = normalize_df_price(df_price)\n",
    "        df_price = df_price.mul(df_weights[f\"weight_{j}\"], axis=0)\n",
    "        df_price = df_price.fillna(df_price.mean(numeric_only=True))\n",
    "        df_price = df_price.rename(columns=lambda x: f\"{tick}_{x}_{j}\")  # optional\n",
    "        \n",
    "        # (input) horizontally concat -> collect\n",
    "        df = pd.concat([df, df_price], axis=1)\n",
    "\n",
    "        # (output)\n",
    "        df_price = price_df_dict[tick]\n",
    "        df_price = df_price[(date_end <= df_price[\"date\"]) & (df_price[\"date\"] < pred_end)]\n",
    "        df_price = df_price.reset_index(drop=True)\n",
    "        df_price = fix_missing_len(df_price, pred_days)\n",
    "        assert df_price.shape == (pred_days, df_price.shape[1])\n",
    "        price_series = (df_price[\"open\"] + df_price[\"close\"]) / 2\n",
    "        price_ratio_series = price_series.diff()[1:].reset_index(drop=True) / price_series[:-1]\n",
    "        assert len(price_ratio_series) == pred_days - 1  # e.g. 30 days -> 29 ratios\n",
    "        price_ratio_window_list.append(price_ratio_series)\n",
    "\n",
    "    df = df.drop(columns=[\"dummy\"])\n",
    "    dataset.append(df.to_numpy())\n",
    "    # add cash ratio\n",
    "    price_ratio_window_list.append(np.array([0.0] * (pred_days - 1)))  # add cash ratio\n",
    "    price_ratio_list.append(np.stack(price_ratio_window_list, axis=0))  # (num_tickers + 1, pred_days - 1)\n",
    "\n",
    "dataset = np.stack(dataset, axis=0)\n",
    "np.save(os.path.join(output_dir, \"dataset.npy\"), dataset)\n",
    "print(dataset.shape)  # (num_samples, window_size, total_features)\n",
    "\n",
    "json.dump(meta_list, open(os.path.join(output_dir, \"meta.json\"), \"w\"), indent=4)\n",
    "print(len(meta_list), meta_list[0])  # (nums_samples, {...})\n",
    "\n",
    "price_ratio_list = np.stack(price_ratio_list, axis=0)\n",
    "np.save(os.path.join(output_dir, \"price_ratio.npy\"), price_ratio_list)\n",
    "print(price_ratio_list.shape)  # (num_samples, num_tickers + 1, pred_days - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(dataset)), np.sum(np.isnan(price_ratio_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b23eb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(price_ratio_list[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5f73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5791eda",
   "metadata": {},
   "source": [
    "#### Output calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f62f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(transaction_fee_rate: float = 0.0002, price_ratio_window = price_ratio_list[0]):\n",
    "    ticks_add1, pred_days_minus1 = price_ratio_window.shape\n",
    "    pred_days = pred_days_minus1 + 1\n",
    "    model_output = (np.random.random((pred_days, ticks_add1)) - 0.5) * 3\n",
    "    #print(model_output.shape, price_ratio_window.shape)  # (30, 16), (16, 29)\n",
    "    #raise\n",
    "    \n",
    "    # change the last column (cash) to be non-negative\n",
    "    model_output[:, -1] = np.abs(model_output[:, -1])\n",
    "    \n",
    "    # init investment combination for days\n",
    "    comb_for_days = model_output / model_output.sum(axis=1, keepdims=True)\n",
    "    assert np.abs(comb_for_days.sum(axis=1).sum() - 1 * pred_days) < 1e-6\n",
    "\n",
    "    # iterate days for changing\n",
    "    money_comb = comb_for_days[0].copy()\n",
    "    money_history = [1]\n",
    "    for day in range(1, pred_days):\n",
    "        # iterate tickers in a day\n",
    "        for i, price_ratio_window in enumerate(price_ratio_window_list):\n",
    "            money_comb[i] = money_comb[i] * (1 + price_ratio_window[day - 1])\n",
    "        turnover = np.abs(comb_for_days[day] - comb_for_days[day - 1]).sum()\n",
    "        money = money_comb.sum()\n",
    "        money = max(1e-12, money - money * turnover * transaction_fee_rate)\n",
    "        money_history.append(float(money))\n",
    "        money_comb = comb_for_days[day] * money  # reweighting\n",
    "    \n",
    "    # compute sharpe ratio\n",
    "    excess_returns = np.array(money_history[1:]) / np.array(money_history[:-1]) - 1\n",
    "    sharpe_ratio = excess_returns.mean() / (excess_returns.std() + 1e-6)\n",
    "    # print(money_history, sharpe_ratio)\n",
    "\n",
    "    return -sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce944ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(transaction_fee_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09e44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "money_list = [gen(transaction_fee_rate=0) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3834d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(money_list, bins=20, kde=True)\n",
    "plt.show()\n",
    "print(np.array(sorted(money_list)[20:-20]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee35566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd2a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
