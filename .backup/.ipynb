{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571860bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_weights_in_window(hist_df_list_seg: List[pd.DataFrame], date_list_seg: List[pd.Timestamp], top_tickers: List[str]) -> pd.DataFrame:\n",
    "#     assert len(hist_df_list_seg) == len(date_list_seg)\n",
    "#     # init\n",
    "#     df_weights = pd.DataFrame(\n",
    "#         {\n",
    "#             \"date\": pd.Series(dtype='datetime64[ns]'),\n",
    "#             **{f\"ticker_{i}\": pd.Series(dtype='str') for i in range(len(top_tickers))},\n",
    "#             **{f\"weight_{i}\": pd.Series(dtype='float') for i in range(len(top_tickers))},\n",
    "#         }\n",
    "#     )\n",
    "#     # iterate all time in a window \n",
    "#     for df, date in zip(hist_df_list_seg, date_list_seg):\n",
    "#         len_df_weights = len(df_weights)\n",
    "#         df_weights.at[len_df_weights, \"date\"] = date\n",
    "#         # iterate all tickers\n",
    "#         cap_sum = df[\"Market Cap\"].sum()\n",
    "#         df[\"Weight\"] = df[\"Market Cap\"] / cap_sum\n",
    "#         tick_cnt = 0\n",
    "#         for _, row in df.iterrows():\n",
    "#             if row[\"Ticker\"] in top_tickers:\n",
    "#                 df_weights.at[len_df_weights, f\"ticker_{tick_cnt}\"] = row[\"Ticker\"]\n",
    "#                 df_weights.at[len_df_weights, f\"weight_{tick_cnt}\"] = row[\"Weight\"]\n",
    "#                 tick_cnt += 1\n",
    "#     return df_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TickerMapping:\n",
    "    hist_to_price_dict = {\"SHIB\": \"1000SHIB\"}\n",
    "    price_to_hist_dict = {\"1000SHIB\": \"SHIB\"}\n",
    "\n",
    "    def hist_to_price(self, ticker: str) -> str:\n",
    "        return self.hist_to_price_dict.get(ticker, ticker)\n",
    "\n",
    "    def price_to_hist(self, ticker: str) -> str:\n",
    "        return self.price_to_hist_dict.get(ticker, ticker)\n",
    "\n",
    "\n",
    "def load_all_price_data(glob_path: str) -> Dict[str, pd.DataFrame]:\n",
    "    ticker_mapping = TickerMapping()\n",
    "    price_data_dict = {}\n",
    "    for xlsx_path in glob.glob(glob_path):\n",
    "        ticker = re.findall(\"(.*)USDT.xlsx\", os.path.basename(xlsx_path))[0]\n",
    "        ticker = ticker_mapping.price_to_hist(ticker)\n",
    "        df = pd.read_excel(xlsx_path)\n",
    "        price_data_dict[ticker] = df\n",
    "    return price_data_dict\n",
    "\n",
    "\n",
    "def get_and_save_extend_describe(df: pd.DataFrame, save_path: str) -> pd.DataFrame:\n",
    "    df_describe = df.describe()\n",
    "    df_describe = df_describe.loc[[\"min\", \"max\"]]\n",
    "    df_describe.loc[\"log_min\"] = df_describe.loc[\"min\"].apply(lambda x: np.log(x) if isinstance(x, np.float64) else None)\n",
    "    df_describe.loc[\"log_max\"] = df_describe.loc[\"max\"].apply(lambda x: np.log(x) if isinstance(x, np.float64) else None)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df_describe.to_csv(save_path)\n",
    "    return df_describe\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NormalizationMapper:\n",
    "    describe_col: str\n",
    "    method: str\n",
    "\n",
    "\n",
    "map_dict_norm = {\n",
    "    \"open\": NormalizationMapper(describe_col=\"open\", method=\"norm\"),\n",
    "    \"high\": NormalizationMapper(describe_col=\"high\", method=\"norm\"),\n",
    "    \"low\": NormalizationMapper(describe_col=\"low\", method=\"norm\"),\n",
    "    \"close\": NormalizationMapper(describe_col=\"close\", method=\"norm\"),\n",
    "    \"volume\": NormalizationMapper(describe_col=\"volume\", method=\"log_norm\"),\n",
    "}\n",
    "map_dict_denorm = {\n",
    "    \"open\": NormalizationMapper(describe_col=\"open\", method=\"denorm\"),\n",
    "    \"high\": NormalizationMapper(describe_col=\"high\", method=\"denorm\"),\n",
    "    \"low\": NormalizationMapper(describe_col=\"low\", method=\"denorm\"),\n",
    "    \"close\": NormalizationMapper(describe_col=\"close\", method=\"denorm\"),\n",
    "    \"volume\": NormalizationMapper(describe_col=\"volume\", method=\"log_denorm\"),\n",
    "}\n",
    "\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self, describe: pd.DataFrame = None):\n",
    "        self.des = describe\n",
    "\n",
    "    def _norm(self, col: str, ser: pd.Series) -> pd.Series:\n",
    "        return (ser - self.des[col][\"min\"]) / (self.des[col][\"max\"] - self.des[col][\"min\"])\n",
    "\n",
    "    def _denorm(self, col: str, ser: pd.Series) -> pd.Series:\n",
    "        return ser * (self.des[col][\"max\"] - self.des[col][\"min\"]) + self.des[col][\"min\"]\n",
    "\n",
    "    def _log_norm(self, col: str, ser: pd.Series) -> pd.Series:\n",
    "        log_ser = np.log(ser)\n",
    "        return (log_ser - self.des[col][\"log_min\"]) / (self.des[col][\"log_max\"] - self.des[col][\"log_min\"])\n",
    "\n",
    "    def _log_denorm(self, col: str, ser: pd.Series) -> pd.Series:\n",
    "        return np.exp(ser * (self.des[col][\"log_max\"] - self.des[col][\"log_min\"]) + self.des[col][\"log_min\"])\n",
    "\n",
    "    def run(self, df: pd.DataFrame, map_dict: Dict[str, NormalizationMapper]) -> pd.DataFrame:\n",
    "        new_df = df.copy()\n",
    "        for col, mapper in map_dict.items():\n",
    "            new_df[col] = getattr(self, f\"_{mapper.method}\")(mapper.describe_col, new_df[col])\n",
    "        return new_df\n",
    "\n",
    "\n",
    "def merge_price_and_weights(df_price: pd.DataFrame, df_weights: pd.DataFrame, ticker: str) -> pd.DataFrame:\n",
    "    df_weights_ticker = df_weights[[\"date\", ticker]].rename(columns={ticker: \"weights\"})\n",
    "    df = df_price.merge(df_weights_ticker, how=\"left\", on=\"date\")\n",
    "    df[\"weights\"] = df[\"weights\"].ffill().bfill()\n",
    "    date_col = df.pop(\"date\")\n",
    "    df[\"date\"] = date_col\n",
    "    return df\n",
    "\n",
    "\n",
    "window_size = 13  # 13 weeks (three month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data_dict = load_all_price_data(\"/app/dataset/raw/20250928_现货价格数据和历史排名数据/price_data/*.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3071fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_weights) - window_size + 1):\n",
    "    df_weights_window = df_weights[i : i + window_size]\n",
    "    print(df_weights_window)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_mapping = TickerMapping()\n",
    "# for xlsx_path in sorted(glob.glob(\"/app/dataset/raw/20250928_现货价格数据和历史排名数据/price_data/*.xlsx\")):\n",
    "#     ticker = re.findall(\"(.*)USDT.xlsx\", os.path.basename(xlsx_path))[0]\n",
    "#     ticker = ticker_mapping.price_to_hist(ticker)\n",
    "\n",
    "#     # normalization\n",
    "#     df = pd.read_excel(xlsx_path)\n",
    "#     df_describe = get_and_save_extend_describe(df, f\"{output_dir}/describe/{ticker}.csv\")\n",
    "#     normalizer = Normalizer(df_describe)\n",
    "#     df_norm = normalizer.run(df, map_dict_norm)\n",
    "    \n",
    "#     # merge weights\n",
    "#     df = merge_price_and_weights(df_norm, df_weights, ticker)\n",
    "#     print(df)\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip row sign if sum < 0\n",
    "        row_sums = model_output.sum(dim=1, keepdim=True)\n",
    "        mask = (row_sums < 0).float()\n",
    "        multiplier = 1 - 2 * mask\n",
    "        model_output_new = model_output * multiplier"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
